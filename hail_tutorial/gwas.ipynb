{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GWAS with Hail"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook shows how to perform a GWAS for 1 caseâ€“control trait using Firth's logistic regression with Hail and save the results as a Hail Table to an Apollo database (dnax://) on the DNAnexus platform. See documentation for guidance on launch specs for the JupyterLab with Spark Cluster app for different data sizes: https://documentation.dnanexus.com/science/using-hail-to-analyze-genomic-data\n",
        "\n",
        "Note: For population scale data, samples may be referred to as individuals. In this notebook, the word \"sample\" will be used.\n",
        "\n",
        "Pre-conditions for running this notebook successfully:\n",
        "- There is an existing Hail MatrixTable in DNAX\n",
        "- There is an existing variant QC Table in DNAX (see *pre-GWAS with Hail: Locus QC*)\n",
        "- There is an existing sample QC Table in DNAX (see *pre-GWAS with Hail: Sample QC*)\n",
        "- There is phenotypic data for the samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Initiate Spark and Hail"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Running this cell will output a red-colored message- this is expected.\n",
        "# The 'Welcome to Hail' message in the output will indicate that Hail is ready to use in the notebook.\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "import hail as hl\n",
        "\n",
        "builder = (\n",
        "    SparkSession\n",
        "    .builder\n",
        "    .enableHiveSupport()\n",
        ")\n",
        "spark = builder.getOrCreate()\n",
        "hl.init(sc=spark.sparkContext)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Read MT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# define MT url\n",
        "\n",
        "mt_url = \"dnax://database-GFpXJ5j0vzZxPZQ2Ggf14x7q/geno.mt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# read MT\n",
        "\n",
        "mt = hl.read_matrix_table(mt_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# View structure of MT before adding pheno data\n",
        "\n",
        "mt.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Create pheno Table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Phenotypic traits data can come from different sources (i.e. Cohorts from the Cohort Browser, separate text file, etc.) In this notebook, we will obtain our pheno data from a CSV file that was uploaded to the project. In this (very basic) example pheno data, we will look at the phenotypic trait `is_case` for each sample. The values will indicate if the sample is a case (`is_case=true`) or a control (`is_case=false`)\n",
        "\n",
        "All data uploaded to the project before running the JupyterLab app is mounted (https://documentation.dnanexus.com/user/jupyter-notebooks?#accessing-data) and can be accessed in `/mnt/project/<path_to_data>`. The file URL follows the format: `file:///mnt/project/<path_to_data>`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Import the pheno CSV file as a Hail Table\n",
        "\n",
        "pheno_table = hl.import_table(\"file:///mnt/project/use_cases/GWAS/pheno.csv\",\n",
        "                              delimiter=',',\n",
        "                              impute=True,\n",
        "                              key='sample_id') # specify the column that will be the key (values must match what is in the MT 's' column)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# View structure of pheno Table\n",
        "\n",
        "pheno_table.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Annotate MT with pheno Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Annotate the MT with pheno Table by matching the MT's column key ('s') with the pheno Table's key ('sample_id')\n",
        "\n",
        "phenogeno_mt = mt.annotate_cols(**pheno_table[mt.s])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# View structure of MT after annotating with pheno Table\n",
        "\n",
        "phenogeno_mt.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that the pheno traits have been added in the column fields of the MT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Filter MT using QC Tables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 5a) Filter locus QC Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Define locus QC Table url\n",
        "\n",
        "locus_qc_url = \"dnax://database-GFpXJ5j0vzZxPZQ2Ggf14x7q/variant_qc.ht\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Read locus QC Table\n",
        "\n",
        "pre_locus_qc_tb = hl.read_table(locus_qc_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# View structure of locus QC Table\n",
        "\n",
        "pre_locus_qc_tb.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's filter for loci that have:\n",
        "- an AF value between 0.001-0.999,\n",
        "- a HWE p-value greater or equal to 1e-10,\n",
        "- a call rate greater or equal to 0.9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Filter QC Table using expressions\n",
        "# Note: Viewing the structure of the locus QC table in from the cell above \n",
        "# shows us that the \"AF\", \"p_value_hwe\", and \"call_rate\" fields are within\n",
        "# the \"variant_qc\" struct field.\n",
        "\n",
        "locus_qc_tb = pre_locus_qc_tb.filter(\n",
        "    (pre_locus_qc_tb[\"variant_qc\"][\"AF\"][0] >= 0.001) & \n",
        "    (pre_locus_qc_tb[\"variant_qc\"][\"AF\"][0] <= 0.999) & \n",
        "    (pre_locus_qc_tb[\"variant_qc\"][\"p_value_hwe\"] >= 1e-10) & \n",
        "    (pre_locus_qc_tb[\"variant_qc\"][\"call_rate\"] >= 0.9)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# View number of loci in QC Table before and after filtering\n",
        "#\n",
        "# Note: running this cell can be computationally expensive and take\n",
        "# longer for bigger datasets (this cell can be commented out).\n",
        "\n",
        "print(f\"Num loci before filtering: {pre_locus_qc_tb.count()}\")\n",
        "print(f\"Num loci after filtering: {locus_qc_tb.count()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 5b) Filter sample QC Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Define sample QC Table url\n",
        "\n",
        "sample_qc_url = \"dnax://database-GFpXJ5j0vzZxPZQ2Ggf14x7q/sample_qc.ht\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Read sample QC Table\n",
        "\n",
        "pre_sample_qc_tb = hl.read_table(sample_qc_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# View structure of sample QC Table\n",
        "\n",
        "pre_sample_qc_tb.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's filter for samples that have a call rate greater or equal to 0.99"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Filter sample QC Table using expressions\n",
        "# Note: Viewing the structure of the sample QC table in from the cell above \n",
        "# shows us that the \"call_rate\" field is within the \"sample_qc\" struct field\n",
        "\n",
        "sample_qc_tb = pre_sample_qc_tb.filter(\n",
        "    pre_sample_qc_tb[\"sample_qc\"][\"call_rate\"] >= 0.99) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# View number of samples in QC Table before and after filtering\n",
        "#\n",
        "# Note: running this cell can be computationally expensive and take\n",
        "# longer for bigger datasets (this cell can be commented out).\n",
        "\n",
        "print(f\"Num samples before filtering: {pre_sample_qc_tb.count()}\")\n",
        "print(f\"Num samples after filtering: {sample_qc_tb.count()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 5c) Filter MT with both QC Tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Filter the MT using the locus QC Table\n",
        "\n",
        "qc_mt = phenogeno_mt.semi_join_rows(locus_qc_tb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Filter the MT using the sample QC Table\n",
        "\n",
        "qc_mt = qc_mt.semi_join_cols(sample_qc_tb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# View MT after QC filters\n",
        "# \n",
        "# Note: running 'mt.rows().count()' or 'mt.cols().count()' can be computationally \n",
        "# expensive and take longer for bigger datasets (these lines can be commented out).\n",
        "\n",
        "print(f\"Num partitions: {qc_mt.n_partitions()}\")\n",
        "print(f\"Num loci: {qc_mt.rows().count()}\")\n",
        "print(f\"Num samples: {qc_mt.cols().count()}\")\n",
        "qc_mt.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Run GWAS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Additional documentation: https://hail.is/docs/0.2/methods/stats.html#hail.methods.logistic_regression_rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Run Hail's logistic regression method\n",
        "\n",
        "gwas = hl.logistic_regression_rows(test=\"firth\",\n",
        "                                   y=qc_mt.is_case, # the column field of the pheno trait we are looking at ('is_case')\n",
        "                                   x=qc_mt.GT.n_alt_alleles(), # n_alt_alleles() returns the count of non-reference alleles\n",
        "                                   covariates=[1.0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# View structure of GWAS results Table\n",
        "\n",
        "gwas.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Save GWAS results Table in Apollo Database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Define database and table name\n",
        "\n",
        "db_name = \"database_name\"\n",
        "tb_name = \"gwas.ht\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Create database in DNAX\n",
        "\n",
        "stmt = f\"CREATE DATABASE IF NOT EXISTS {db_name} LOCATION 'dnax://'\"\n",
        "print(stmt)\n",
        "spark.sql(stmt).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Store Table in DNAX\n",
        "\n",
        "import dxpy\n",
        "\n",
        "# find database ID of newly created database using a dxpy method\n",
        "db_uri = dxpy.find_one_data_object(name=f\"{db_name}\", classname=\"database\")['id']\n",
        "url = f\"dnax://{db_uri}/{tb_name}\"\n",
        "\n",
        "# Before this step, the Hail Table is just an object in memory. To persist it and be able to access \n",
        "# it later, the notebook needs to write it into a persistent filesystem (in this case DNAX).\n",
        "# See https://hail.is/docs/0.2/hail.Table.html#hail.Table.write for additional documentation.\n",
        "gwas.write(url) # Note: output should describe size of Table (i.e. number of rows, partitions)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
