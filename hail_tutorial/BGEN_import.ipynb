{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import BGEN Genomic Data with Hail"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook shows how to import genomic data from BGEN files into a Hail MatrixTable and save it to an Apollo database (dnax://) on the DNAnexus platform. See documentation for guidance on launch specs for the JupyterLab with Spark Cluster app for different data sizes: https://documentation.dnanexus.com/science/using-hail-to-analyze-genomic-data\n",
        "\n",
        "Pre-conditions for running this notebook successfully:\n",
        "- BGEN file(s) are uploaded to the project\n",
        "- If data is spread across multiple BGEN files, they should be organized into one directory in the project and have unique file names\n",
        "- BGEN file(s) end in `.bgen`\n",
        "- BGEN file(s) should have an accompanying `.sample` file if sample identifiers are not stored in the BGEN file\n",
        "- BGEN file(s) are `zlib` compressed. Currently, Hail only supports `zlib` compression (does not support `zstd` compression): https://discuss.hail.is/t/index-bgen-zlib-compression-exception/2652"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Initiate Spark and Hail"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Running this cell will output a red-colored message- this is expected.\n",
        "# The 'Welcome to Hail' message in the output will indicate that Hail is ready to use in the notebook.\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "import hail as hl\n",
        "import os\n",
        "\n",
        "builder = (\n",
        "    SparkSession\n",
        "    .builder\n",
        "    .enableHiveSupport()\n",
        ")\n",
        "spark = builder.getOrCreate()\n",
        "hl.init(sc=spark.sparkContext)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Locate and import data into a Hail MatrixTable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "All data uploaded to the project before running the JupyterLab app is mounted (https://documentation.dnanexus.com/user/jupyter-notebooks?#accessing-data) and can be accessed in `/mnt/project/<path_to_data>`. The file URL follows the format: `file:///mnt/project/<path_to_data>`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*If the required Hail-specific index files for each BGEN file have been uploaded onto the platform skip to step 2c in this notebook. Note: The directory of index files for each BGEN file must end in `.idx2` and each directory must contain 2 files: `index` and `metadata.json.gz`.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Define the path of BGEN files directory in the project\n",
        "\n",
        "bgen_path = \"/mnt/project/use_cases/BGEN/data/multiple_chromosomes\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2a) Create index files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If there are no Hail-specific index files for each BGEN, they will need to be created using Hail's `index_bgen()` method. If creating index files within this notebook, the index files must be written out to HDFS so that the data is available on all nodes. The HDFS URL should follow the following format: `hdfs:///<name_of_bgen_file>.idx2` (the index file(s) must end with the extension `.idx2`).\n",
        "\n",
        "Notes from Hail documentation:\n",
        "- Hail only supports 8-bit probabilities (If using qctools to convert a VCF into BGEN, use the option `-bgen-bits 8`).\n",
        "- While the `index_bgen()` method parallelizes over a list of BGEN files, each file is indexed serially by one core. Indexing several BGEN files on a large cluster is a waste of resources, so indexing should generally be done once, separately from large analyses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Create an index file for each BGEN file in the directory\n",
        "\n",
        "for filename in os.listdir(bgen_path):\n",
        "    file_url = f\"file://{bgen_path}/{filename}\"\n",
        "    hl.index_bgen(path=file_url,\n",
        "                  index_file_map={file_url:f\"hdfs:///{filename}.idx2\"},\n",
        "                  reference_genome=\"GRCh38\",\n",
        "                  contig_recoding=None,\n",
        "                  skip_invalid_loci=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2b) Create index file map dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Create the index file map necessary for importing\n",
        "\n",
        "index_file_map = {}\n",
        "for filename in os.listdir(bgen_path):\n",
        "    index_file_map[f\"file://{bgen_path}/{filename}\"] = f\"hdfs:///{filename}.idx2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# If index files were created outside of this notebook, manually create the index_file_map dictionary using file URLs\n",
        "#\n",
        "# Example:\n",
        "# index_file_map = {\"file:///mnt/project/use_cases/BGEN/data/indexed_data/chr1.bgen\":\"file:///mnt/project/use_cases/BGEN/data/indexed_data/chr1.bgen.idx2\",\n",
        "#                   \"file:///mnt/project/use_cases/BGEN/data/indexed_data/chr2.bgen\":\"file:///mnt/project/use_cases/BGEN/data/indexed_data/chr2.bgen.idx2\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2c) Import BGEN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "mt = hl.import_bgen(path=f\"file://{bgen_path}/*.bgen\", # regex can be used if genomic data is in multiple BGEN files\n",
        "                    entry_fields=['GT', 'GP'],\n",
        "                    sample_file=f\"file://{bgen_path}/*.sample\",\n",
        "                    n_partitions=None,\n",
        "                    block_size=None,\n",
        "                    index_file_map=index_file_map,\n",
        "                    variants=None,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# View basic properties of MT\n",
        "# \n",
        "# Note: running 'mt.rows().count()' or 'mt.cols().count()' can be computationally \n",
        "# expensive and take longer for bigger datasets.\n",
        "\n",
        "print(f\"Num partitions: {mt.n_partitions()}\")\n",
        "mt.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Store Hail MT in DNAX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Define database and MT names\n",
        "\n",
        "# Note: It is recommended to only use lowercase letters for the database name.\n",
        "# If uppercase lettering is used, the database name will be lowercased when creating the database.\n",
        "db_name = \"database_name\"\n",
        "mt_name = \"geno.mt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Create database in DNAX\n",
        "\n",
        "stmt = f\"CREATE DATABASE IF NOT EXISTS {db_name} LOCATION 'dnax://'\"\n",
        "print(stmt)\n",
        "spark.sql(stmt).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Store MT in DNAX\n",
        "\n",
        "import dxpy\n",
        "\n",
        "# Find database ID of newly created database using dxpy method\n",
        "db_uri = dxpy.find_one_data_object(name=f\"{db_name}\", classname=\"database\")['id']\n",
        "url = f\"dnax://{db_uri}/{mt_name}\" # Note: the dnax url must follow this format to properly save MT to DNAX\n",
        "\n",
        "# Before this step, the Hail MatrixTable is just an object in memory. To persist it and be able to access \n",
        "# it later, the notebook needs to write it into a persistent filesystem (in this case DNAX).\n",
        "# See https://hail.is/docs/0.2/hail.MatrixTable.html#hail.MatrixTable.write for additional documentation.\n",
        "mt.write(url) # Note: output should describe size of MT (i.e. number of rows, columns, partitions) "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
