{"metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.5"}}, "nbformat_minor": 4, "nbformat": 4, "cells": [{"cell_type": "markdown", "source": "# UK Biobank RAP - Basic data extraction\n\n\nThis notebook is delivered \"As-Is\". Notwithstanding anything to the contrary, DNAnexus will have no warranty, support or other obligations with respect to Materials provided hereunder.\n\n[MIT License](https://github.com/dnanexus/OpenBio/blob/master/LICENSE.md) applies to this notebook.", "metadata": {}}, {"cell_type": "markdown", "source": "### Prologue", "metadata": {}}, {"cell_type": "markdown", "source": "This prologue has been created for consistency across notebooks, and to improve notebook portability across projects.", "metadata": {}}, {"cell_type": "code", "source": "# Import packages\nimport pyspark\nimport dxpy\nimport dxdata", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "# Spark initialization (Done only once; do not rerun this cell unless you select Kernel -> Restart kernel).\nsc = pyspark.SparkContext()\nspark = pyspark.sql.SparkSession(sc)", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "# Automatically discover dispensed database name and dataset id\ndispensed_database_name = dxpy.find_one_data_object(classname=\"database\", name=\"app*\", folder=\"/\", name_mode=\"glob\", describe=True)[\"describe\"][\"name\"]\ndispensed_dataset_id = dxpy.find_one_data_object(typename=\"Dataset\", name=\"app*.dataset\", folder=\"/\", name_mode=\"glob\")[\"id\"]", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": "## Access dataset", "metadata": {}}, {"cell_type": "code", "source": "dataset = dxdata.load_dataset(id=dispensed_dataset_id)", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": "### Dataset \"entities\" are virtual tables linked to one another.\n\nThe main entity is \"participant\" and corresponds to most pheno fields. Additional entities correspond to linked health care data.\nEntities starting with \"hesin\" are for hospital records; entities starting with \"gp\" are for GP records, etc.", "metadata": {}}, {"cell_type": "code", "source": "dataset.entities", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": "### Accessing the main 'participant' entity", "metadata": {}}, {"cell_type": "code", "source": "participant = dataset[\"participant\"]", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": "#### Selecting participant fields by field index, instance index, array index\n\nFor the main participant data, the Platform uses field names with the following convention:\n\n|Type of field|Syntax for field name|Example|\n|:------------|---------------------|-------|\n|Neither instanced nor arrayed|`p<FIELD-ID>`|`p31`|\n|Instanced but not arrayed|`p<FIELD-ID>_i<INSTANCE-ID>`|`p40005_i0`|\n|Arrayed but not instanced|`p<FIELD-ID>_a<ARRAY-ID>`|`p41262_a0`|\n|Instanced and arrayed|`p<FIELD-ID>_i<INSTANCE-ID>_a<ARRAY-ID>`|`p93_i0_a0`|\n\nLastly, the participant id field itself (EID) is named `eid`\n\nIf you know exactly the field names you want to work with, put them in a string array (we will see later how to use that):", "metadata": {}}, {"cell_type": "code", "source": "field_names = [\"eid\", \"p31\", \"p21022\", \"p40005_i0\", \"p93_i0_a0\"]", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": "#### Looking up fields by id\n\nIf you know the field id but you are not sure if it is instanced or arrayed, and want to grab all instances/arrays (if any), use these:", "metadata": {}}, {"cell_type": "code", "source": "# Returns all fields for a given UK Biobank data-field id\n\ndef fields_for_id(field_id):\n    from distutils.version import LooseVersion\n    field_id = str(field_id)\n    fields = participant.find_fields(name_regex=r'^p{}(_i\\d+)?(_a\\d+)?$'.format(field_id))\n    return sorted(fields, key=lambda f: LooseVersion(f.name))\n\n# Returns all field names for a given UK Biobank data-field id\n\ndef field_names_for_id(field_id):\n    return [f.name for f in fields_for_id(field_id)]", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": "##### Examples:", "metadata": {}}, {"cell_type": "code", "source": "# Participant sex\nfield_names_for_id(\"31\")", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "# Age when attending assessment centre has multiple instances (visits) \nfield_names_for_id(\"21003\")", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "# Pulse rate has multiple instances and array indices (measured twice in each visit)\nfield_names_for_id(\"102\")", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": "#### Looking up fields by title keyword\n\nIf you remember part of the field title, use these:", "metadata": {}}, {"cell_type": "code", "source": "# Returns all field objects for a given title keyword\n\ndef fields_by_title_keyword(keyword):\n    from distutils.version import LooseVersion\n    fields = list(participant.find_fields(lambda f: keyword.lower() in f.title.lower()))\n    return sorted(fields, key=lambda f: LooseVersion(f.name))\n\n# Returns all field names for a given title keyword\n\ndef field_names_by_title_keyword(keyword):\n    return [f.name for f in fields_by_title_keyword(keyword)]\n\n# Returns all field titles for a given title keyword\n\ndef field_titles_by_title_keyword(keyword):\n    return [f.title for f in fields_by_title_keyword(keyword)]", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "field_titles_by_title_keyword('standing height')", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "field_names_by_title_keyword('standing height')", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": "#### You can mix and match these methods to end up with a list of field names of interest:", "metadata": {}}, {"cell_type": "code", "source": "field_names = [\"eid\", \"p31\", \"p21022\"] + field_names_for_id(\"41262\") + field_names_by_title_keyword('diagnoses - main')", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": "### Grabbing fields into a spark dataframe\n\n`retrieve_fields` function allows you to get subset of data into tabular format. \n\nYou can set `coding_values` parameter as:\n- \"raw\" (default: leave coded values as they are)\n- \"exclude\" (if sparse-coded, treat codes as missing data by replacing with null)\n- \"replace\" (replace coded values with their meanings)", "metadata": {}}, {"cell_type": "code", "source": "df = participant.retrieve_fields(names=field_names, engine=dxdata.connect())", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "# See the first five entries as a Spark DataFrame:\ndf.show(5, truncate=False)", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "# See the first five entries as a Pandas DataFrame:\ndf.limit(5).toPandas()", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": "### Filtering spark dataframes\n\nSpark dataframes can be filtered using the syntax: `df.filter(expression)`\n\nThe expression can be either :\n\n* a string expression, built using SQL fields (e.g. `p31`) and SQL operators (e.g. `=`, `NOT`, `OR`, `AND`)\n  * example: `\"(p21022 >= 50) AND (p31 = 0)\"`\n  \n\n* a Python expression, built using Python object fields (e.g. `df.p31`) and Python operators (e.g. `==`, `!`, `|`, `&`)\n  * example: `(df.p21022 >= 50) & (df.p31 == 0)`", "metadata": {}}, {"cell_type": "markdown", "source": "#### Example: Participants above 50 years old and female", "metadata": {}}, {"cell_type": "code", "source": "df.count()", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "# Using SQL syntax\ndf.filter(\"(p21022 >= 50) AND (p31 = 0)\").count()", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "# Using Python syntax\ndf.filter((df.p21022 >= 50) & (df.p31 == 0)).count()", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": "#### Working with codings", "metadata": {}}, {"cell_type": "code", "source": "participant[\"p31\"].coding", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "participant[\"p31\"].coding.codes", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "def field_codes_by_keyword(field_name, keyword):\n    return dict([(k,v) for (k,v) in participant[field_name].coding.codes.items() if keyword.lower() in v.lower()])", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "field_codes_by_keyword(\"p31\", \"female\")", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "field_codes_by_keyword(\"p41202\", \"obesity\")", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": "### Getting information about the fields", "metadata": {}}, {"cell_type": "code", "source": "# get link to UKB documentation page\nparticipant[\"p31\"].linkout", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "# Get field units\nparticipant[\"p21022\"].units", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": "### Saving results", "metadata": {}}, {"cell_type": "code", "source": "# Saving as CSV file\ndf.toPandas().to_csv('results.csv', index=False)", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "# Saving as TSV file\ndf.toPandas().to_csv('results.tsv', sep='\\t', index=False)", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "# Saving as DTA file (Stata)\ndf.toPandas().astype(str).replace('None|NaN|nan', '.', regex=True).to_stata('results.dta')", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": "#### Writing results back to the project", "metadata": {}}, {"cell_type": "code", "source": "%%bash\ndx upload results.tsv --dest / ", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "", "metadata": {}, "execution_count": null, "outputs": []}]}