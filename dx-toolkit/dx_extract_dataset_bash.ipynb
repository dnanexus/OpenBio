{"metadata": {"kernelspec": {"display_name": "Bash", "language": "bash", "name": "bash"}, "language_info": {"codemirror_mode": "shell", "file_extension": ".sh", "mimetype": "text/x-sh", "name": "bash"}}, "nbformat_minor": 5, "nbformat": 4, "cells": [{"cell_type": "markdown", "source": "# \u201cdx extract_dataset\u201d in Bash\n<hr/>\n***As-Is Software Disclaimer***\n\nThis content in this repository is delivered \u201cAs-Is\u201d. Notwithstanding anything to the contrary, DNAnexus will have no warranty, support, liability or other obligations with respect to Materials provided hereunder.\n\n<hr/>\n\nThis notebook demonstrates usage of the dx command `extract_dataset` for:\n* Retrieval of Apollo-stored data, as referenced within entities and fields of a Dataset or Cohort object on the platform\n* Retrieval of the underlying data dictionary files used to generate a Dataset object on the platform\n\n<a href=\"https://github.com/dnanexus/OpenBio/blob/master/LICENSE.md\">MIT License</a> applies to this notebook.", "metadata": {}, "id": "70230d90"}, {"cell_type": "markdown", "source": "## Preparing your environment\n### Launch spec:\n\n* App name: JupyterLab with Python, R, Stata, ML ()\n* Kernel: Bash\n* Instance type: mem1_ssd1_v2_x2\n* Cost: < $0.2\n* Runtime: =~ 10 min\n* Data description: Input for this notebook is a v3.0 Dataset or Cohort object ID", "metadata": {}, "id": "06fc0571"}, {"cell_type": "markdown", "source": "### dxpy version\nextract_dataset requires dxpy version >= 0.329.0. However, a more recent version of dxpy on PyPI may already be available and installed, making the below \"pip\" install unecessary. If running the command from your local environment (i.e. off of the DNAnexus platform), it may be required to also install pandas. For example, pip3 install -U dxpy[pandas]\nListing options are available in dxpy version >= 0.341.0 ", "metadata": {}, "id": "83a28ced"}, {"cell_type": "code", "source": "pip3 install -U dxpy==0.363.0\ndx --version", "metadata": {"tags": []}, "execution_count": null, "outputs": [], "id": "bb2510d0"}, {"cell_type": "markdown", "source": "### 1. Assign environment variables", "metadata": {}, "id": "fd0a56a6"}, {"cell_type": "code", "source": "# The referenced Dataset is private and provided only to demonstrate an example input. The user will need to supply a permissible and valid record-id\n# Assign joint dataset project-id:record-id\ndataset=\"project-G5BzYk80kP5bvbXy5J7PQZ36:record-GJ3Y7jQ0VKyy592yPxB4yG7Y\"", "metadata": {"tags": []}, "execution_count": null, "outputs": [], "id": "78bf4a9f"}, {"cell_type": "markdown", "source": "### 2. Inspecting the dataset structure", "metadata": {}, "id": "05e0d272"}, {"cell_type": "markdown", "source": "#### A) Extract the three dictionary files\n`<record_name>.data_dictionary.csv`, `<record_name>.entity_dictionary.csv`, and `<record_name>.codings.csv`", "metadata": {}, "id": "6a1f2cb9"}, {"cell_type": "code", "source": "dx extract_dataset ${dataset} -ddd --delimiter \",\"", "metadata": {"tags": []}, "execution_count": null, "outputs": [], "id": "5c683975"}, {"cell_type": "markdown", "source": "#### Preview data in the three dictionary (*.csv) files", "metadata": {}, "id": "b86447e1"}, {"cell_type": "code", "source": "head -5 *.csv", "metadata": {"tags": []}, "execution_count": null, "outputs": [], "id": "a36f3be7"}, {"cell_type": "markdown", "source": "#### B) List names and titles for entities and fields \nNames and titles are printed as tab separated columns.", "metadata": {}, "id": "176f0dd8"}, {"cell_type": "code", "source": "dx extract_dataset ${dataset} --list-entities", "metadata": {"tags": []}, "execution_count": null, "outputs": [], "id": "fcd4fd2d"}, {"cell_type": "markdown", "source": "Listing fields in the main entity.", "metadata": {}, "id": "5a54604c"}, {"cell_type": "code", "source": "dx extract_dataset ${dataset} --list-fields", "metadata": {"tags": []}, "execution_count": null, "outputs": [], "id": "69064683"}, {"cell_type": "markdown", "source": "Listing fields in the specified entities. ", "metadata": {}, "id": "66211987"}, {"cell_type": "code", "source": "dx extract_dataset ${dataset} --list-fields --entities=doctor,baseline", "metadata": {"tags": []}, "execution_count": null, "outputs": [], "id": "8e31d232"}, {"cell_type": "markdown", "source": "### 3. Parse metadata to get entity/field names in format for extraction", "metadata": {}, "id": "5177e4f3"}, {"cell_type": "markdown", "source": "#### A) Parsing dictionary files", "metadata": {}, "id": "ebe21011"}, {"cell_type": "code", "source": "entity_field_input=`cut -d \",\" -f 1,2 *.data_dictionary.csv | tail -n +2 | tr ',' '.'| tr '\\n' ',' | sed 's/.$//'`\necho ${entity_field_input}", "metadata": {"tags": []}, "execution_count": null, "outputs": [], "id": "92374fb2"}, {"cell_type": "markdown", "source": "#### B) Parsing output of `dx extract_dataset ${dataset} --list-fields` \nThis can be further processed to filter the fileds of interest e.g.", "metadata": {}, "id": "6fcb75fa"}, {"cell_type": "code", "source": "entity_field_input=`dx extract_dataset ${dataset} --list-fields |cut -f1 |grep risk |tr '\\n' ',' |sed 's/.$//'`\necho ${entity_field_input}", "metadata": {"tags": []}, "execution_count": null, "outputs": [], "id": "cea9f28e"}, {"cell_type": "markdown", "source": "### 4. Use extracted entity and field names as input to the called function, \u201cdx extract_dataset\u201d and extract data", "metadata": {}, "id": "d43ccb2e"}, {"cell_type": "code", "source": "dx extract_dataset \"${dataset}\" --fields \"${entity_field_input}\" -o extracted_data.csv", "metadata": {"tags": []}, "execution_count": null, "outputs": [], "id": "73f1281d"}, {"cell_type": "markdown", "source": "#### Print data in the retrieved data file", "metadata": {}, "id": "92687ea4"}, {"cell_type": "code", "source": "head -3 extracted_data.csv", "metadata": {"tags": []}, "execution_count": null, "outputs": [], "id": "48957d8f-fb69-402b-916f-c02cbe25c9dc"}, {"cell_type": "markdown", "source": "#### Alternitavely, save the extracted entity into a file and supply it by using \"--fields-file\" option", "metadata": {}, "id": "78db7363-14d1-4a04-82ce-1b03808f14d2"}, {"cell_type": "code", "source": "echo \"$entity_field_input\" | sed 's/,/\\n/g' > entity_field_input_file.txt\n\ndx extract_dataset \"${dataset}\" --fields-file entity_field_input_file.txt -o extracted_data_entity_field_input_file.csv\nhead -3 extracted_data_entity_field_input_file.csv", "metadata": {"tags": []}, "execution_count": null, "outputs": [], "id": "4b5326cd-3ffe-4534-96d9-cc67032d4354"}, {"cell_type": "markdown", "source": "### 5. Upload extracted dictionaries and data back to the project", "metadata": {}, "id": "799f3229"}, {"cell_type": "code", "source": "dx upload *.csv", "metadata": {"tags": []}, "execution_count": null, "outputs": [], "id": "6e756eb9"}, {"cell_type": "code", "source": "", "metadata": {}, "execution_count": null, "outputs": [], "id": "9fe1e085-b989-4768-9687-8f11c13187ca"}]}