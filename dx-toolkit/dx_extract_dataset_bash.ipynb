{"metadata": {"kernelspec": {"display_name": "Bash", "language": "bash", "name": "bash"}, "language_info": {"codemirror_mode": "shell", "file_extension": ".sh", "mimetype": "text/x-sh", "name": "bash"}}, "nbformat_minor": 5, "nbformat": 4, "cells": [{"cell_type": "markdown", "source": "# \u201cdx extract_dataset\u201d in Bash\n<hr/>\n***As-Is Software Disclaimer***\n\nThis content in this repository is delivered \u201cAs-Is\u201d. Notwithstanding anything to the contrary, DNAnexus will have no warranty, support, liability or other obligations with respect to Materials provided hereunder.\n\n<hr/>\n\nThis notebook demonstrates usage of the dx command `extract_dataset` for:\n* Retrieval of Apollo-stored data, using a dataset or cohort, and for a set of entities and fields.\n* Retrieval of data dictionary files supporting a dataset\n\n<a href=\"https://github.com/dnanexus/OpenBio/blob/master/LICENSE.md\">MIT License</a> applies to this notebook.", "metadata": {}}, {"cell_type": "markdown", "source": "## Preparing your environment\n### Launch spec:\n\n* App name: JupyterLab with Python, R, Stata, ML ()\n* Kernel: Bash\n* Instance type: mem1_ssd1_v2_x2\n* Cost: < $0.2\n* Runtime: =~ 10 min\n* Data description: Input for this notebook is a v3.0 Dataset or Cohort object ID (project-id:record-id where \":record-id\" indicates the current selected project) or name", "metadata": {}}, {"cell_type": "markdown", "source": "### Install dxpy\nextract_dataset requires dxpy version >= 0.329.0. Current version of dxpy in Jupyterlab is 0.314.0. Update dxpy by running `pip3 install -U dxpy[pandas]` in the terminal.", "metadata": {}}, {"cell_type": "markdown", "source": "### 1. Assign environment variables", "metadata": {}}, {"cell_type": "code", "source": "# Assign project-id of dataset\npid=project-G5BzYk80kP5bvbXy5J7PQZ36\n# Assign dataset record-id\nrid=record-GJ3Y7jQ0VKyy592yPxB4yG7Y\n# Assign joint dataset project-id:record-id\ndataset=\"${pid}:${rid}\"", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": "### 2. Call \u201cdx extract_dataset\u201d using a supplied dataset", "metadata": {}}, {"cell_type": "code", "source": "dx extract_dataset ${dataset} -ddd --delimiter \",\"", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": "#### Preview data in the three dictionary (*.csv) files", "metadata": {}}, {"cell_type": "code", "source": "head -5 *.csv", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": "### 3. Parse returned metadata and extract entity/field names", "metadata": {}}, {"cell_type": "code", "source": "entity_field=()\nwhile IFS=\",\" read -r entity field\ndo\n    entity_field+=(\"${entity}.${field}\")\ndone < <(cut -d \",\" -f 1,2 *.data_dictionary.csv | tail -n +2)\necho ${entity_field[@]:0:10}", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": "### 4. Use extracted entity and field names as input to the called function, \u201cdx extract_dataset\u201d and extract data", "metadata": {}}, {"cell_type": "code", "source": "entity_field_input=$(IFS=, ; echo \"${entity_field[*]}\")\necho ${entity_field_input}", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "dx extract_dataset ${dataset} --fields ${entity_field_input} -o extracted_data.csv", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": "#### Print data in the retrieved data file", "metadata": {}}, {"cell_type": "code", "source": "head -3 extracted_data.csv", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": "### 5. Upload extracted dictionaries and data back to the project", "metadata": {}}, {"cell_type": "code", "source": "dx upload *.csv", "metadata": {}, "execution_count": null, "outputs": []}]}